{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "Test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>line_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>verb_percentage</th>\n",
       "      <th>adj_percentage</th>\n",
       "      <th>stopword_percentage</th>\n",
       "      <th>punctuation_percentage</th>\n",
       "      <th>number_percentage</th>\n",
       "      <th>proper_noun_percentage</th>\n",
       "      <th>line_length_trans</th>\n",
       "      <th>verb_percentage_trans</th>\n",
       "      <th>stopword_percentage_trans</th>\n",
       "      <th>punctuation_percentage_trans</th>\n",
       "      <th>word_count_trans</th>\n",
       "      <th>adj_percentage_trans</th>\n",
       "      <th>number_percentage_trans</th>\n",
       "      <th>proper_noun_percentage_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.245731</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71</td>\n",
       "      <td>15</td>\n",
       "      <td>6.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>6.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.531531</td>\n",
       "      <td>2.48998</td>\n",
       "      <td>2.366432</td>\n",
       "      <td>1.183216</td>\n",
       "      <td>1.034220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.837091</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.7</td>\n",
       "      <td>1.174619</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.472136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.167007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.430969</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.684031</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.311019</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.588436</td>\n",
       "      <td>1.209504</td>\n",
       "      <td>4.641589</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   line_length  word_count  verb_percentage  adj_percentage  \\\n",
       "0            9           1              0.0             0.0   \n",
       "1           71          15              6.2             0.0   \n",
       "2            5           2              0.0             0.0   \n",
       "3           36           4              0.0            50.0   \n",
       "4           15           1              0.0           100.0   \n",
       "\n",
       "   stopword_percentage  punctuation_percentage  number_percentage  \\\n",
       "0                  0.0                     0.0                0.0   \n",
       "1                  5.6                     1.4                6.2   \n",
       "2                 20.0                     0.0                0.0   \n",
       "3                  0.0                     0.0                0.0   \n",
       "4                  0.0                     6.7                0.0   \n",
       "\n",
       "   proper_noun_percentage  line_length_trans  verb_percentage_trans  \\\n",
       "0                     0.0           1.245731                0.00000   \n",
       "1                    25.0           1.531531                2.48998   \n",
       "2                    66.7           1.174619                0.00000   \n",
       "3                     0.0           1.430969                0.00000   \n",
       "4                     0.0           1.311019                0.00000   \n",
       "\n",
       "   stopword_percentage_trans  punctuation_percentage_trans  word_count_trans  \\\n",
       "0                   0.000000                      0.000000          0.000000   \n",
       "1                   2.366432                      1.183216          1.034220   \n",
       "2                   4.472136                      0.000000          0.000000   \n",
       "3                   0.000000                      0.000000          0.000000   \n",
       "4                   0.000000                      2.588436          1.209504   \n",
       "\n",
       "   adj_percentage_trans  number_percentage_trans  proper_noun_percentage_trans  \n",
       "0              0.000000                 0.000000                      0.000000  \n",
       "1              0.000000                 1.837091                      5.000000  \n",
       "2              0.000000                 0.000000                      8.167007  \n",
       "3              3.684031                 0.000000                      0.000000  \n",
       "4              4.641589                 0.000000                      0.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_train = pd.read_csv('../output/train_features.csv')\n",
    "resume_val = pd.read_csv('../output/val_features.csv')\n",
    "resume_test = pd.read_csv('../output/test_features.csv')\n",
    "\n",
    "resume_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of features to be used for each dataset\n",
    "raw_features = ['line_length', 'verb_percentage','adj_percentage','stopword_percentage','punctuation_percentage','number_percentage']\n",
    "\n",
    "transformed_features = ['line_length_trans', 'stopword_percentage_trans', 'punctuation_percentage_trans']\n",
    "\n",
    "reduced_features = ['line_length_trans','verb_percentage','stopword_percentage_trans']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write out all data\n",
    "resume_train[raw_features].to_csv('../output/train_features_raw.csv',index=False)\n",
    "resume_val[raw_features].to_csv('../output/val_features_raw.csv',index=False)\n",
    "resume_test[raw_features].to_csv('../output/test_features_raw.csv',index=False)\n",
    "\n",
    "resume_train[transformed_features].to_csv('../output/train_features_trans.csv',index=False)\n",
    "resume_val[transformed_features].to_csv('../output/val_features_trans.csv',index=False)\n",
    "resume_test[transformed_features].to_csv('../output/test_features_trans.csv',index=False)\n",
    "\n",
    "resume_train[all_features].to_csv('../output/train_features_all.csv',index=False)\n",
    "resume_val[all_features].to_csv('../output/val_features_all.csv',index=False)\n",
    "resume_test[all_features].to_csv('../output/test_features_all.csv',index=False)\n",
    "\n",
    "resume_train[reduced_features].to_csv('../output/train_features_reduced.csv',index=False)\n",
    "resume_val[reduced_features].to_csv('../output/val_features_reduced.csv',index=False)\n",
    "resume_test[reduced_features].to_csv('../output/test_features_reduced.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_features = pd.read_csv('output/train_features_raw.csv')\n",
    "train_labels = pd.read_csv('output/train_labels.csv')\n",
    "\n",
    "train_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlation matrix heat map\n",
    "matrix = np.triu(train_features.corr())\n",
    "sns.heatmap(train_features.corr(), annot=True, fmt='.1f', vmin=-1, vmax=1, center=0, cmap='coolwarm', mask=matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV\n",
    "\n",
    "This is LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(results):\n",
    "    print('BEST PARAMS: {}\\n'.format(results.best_params_))\n",
    "    \n",
    "    means = results.cv_results_['mean_test_score']\n",
    "    stds = results.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, results.cv_results_['params']):\n",
    "        print('{} (+/-{}) for {}.'.format(round(mean, 3), round(std*2, 3), params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " # GridSearch\n",
    "# Instantiate a RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "# Create a dictionary with the parameters to check\n",
    "parameters ={\n",
    "    'n_estimators':[2**i for i in range(3,10)],\n",
    "    'max_depth':[2, 4, 8, 16, 32, None]\n",
    "}\n",
    "# Instantiate a GridSearchCV object, passing the RandomForestClassifier, paramaters,\n",
    "# and number of \"K-folds\" (we are using 5)\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "\n",
    "# Like all scikit-learn objects, cv must be fit. Input values must be arrays\n",
    "cv.fit(train_features, train_labels.values.ravel())\n",
    "\n",
    "# This will give us the best hyperparameter settings given this set of data\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature importance plot\n",
    "feat_imp = cv.best_estimator_.feature_importances_\n",
    "indices = np.argsort(feat_imp)\n",
    "plt.yticks(range(len(indices)), [train_features.columns[i] for i in indices])\n",
    "plt.barh(range(len(indices)), feat_imp[indices], color='r', align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Out Pickled Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV automatically makes a best_estimator_ atrribute on a riffiting of the model on 100% of the data\n",
    "joblib.dump(cv.best_estimator_, 'models/mdl_raw_original_features.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat process for other models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformed Features\n",
    "train_features = pd.read_csv('output/train_features_trans.csv')\n",
    "train_labels = pd.read_csv('output/train_labels.csv')\n",
    "\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlation matrix heat map\n",
    "matrix = np.triu(train_features.corr())\n",
    "sns.heatmap(train_features.corr(), annot=True, fmt='.1f', vmin=-1, vmax=1, center=0, cmap='coolwarm', mask=matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # GridSearch\n",
    "rf = RandomForestClassifier()\n",
    "parameters ={\n",
    "    'n_estimators':[2**i for i in range(3,10)],\n",
    "    'max_depth':[2, 4, 8, 16, 32, None]\n",
    "}\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(train_features, train_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate feature importance plot\n",
    "feat_imp = cv.best_estimator_.feature_importances_\n",
    "indices = np.argsort(feat_imp)\n",
    "plt.yticks(range(len(indices)), [train_features.columns[i] for i in indices])\n",
    "plt.barh(range(len(indices)), feat_imp[indices], color='r', align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV automatically makes a best_estimator_ atrribute on a riffiting of the model on 100% of the data\n",
    "joblib.dump(cv.best_estimator_, 'models/mdl_transformed_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Features\n",
    "train_features = pd.read_csv('output/train_features_all.csv')\n",
    "train_labels = pd.read_csv('output/train_labels.csv')\n",
    "\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlation matrix heat map\n",
    "matrix = np.triu(train_features.corr())\n",
    "sns.heatmap(train_features.corr(), annot=True, fmt='.1f', vmin=-1, vmax=1, center=0, cmap='coolwarm', mask=matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # GridSearch\n",
    "rf = RandomForestClassifier()\n",
    "parameters ={\n",
    "    'n_estimators':[2**i for i in range(3,10)],\n",
    "    'max_depth':[2, 4, 8, 16, 32, None]\n",
    "}\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(train_features, train_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature importance plot\n",
    "feat_imp = cv.best_estimator_.feature_importances_\n",
    "indices = np.argsort(feat_imp)\n",
    "plt.yticks(range(len(indices)), [train_features.columns[i] for i in indices])\n",
    "plt.barh(range(len(indices)), feat_imp[indices], color='r', align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV automatically makes a best_estimator_ atrribute on a riffiting of the model on 100% of the data\n",
    "joblib.dump(cv.best_estimator_, 'models/mdl_all_features.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduced Features\n",
    "train_features = pd.read_csv('output/train_features_reduced.csv')\n",
    "train_labels = pd.read_csv('output/train_labels.csv')\n",
    "\n",
    "train_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate correlation matrix heat map\n",
    "matrix = np.triu(train_features.corr())\n",
    "sns.heatmap(train_features.corr(), annot=True, fmt='.1f', vmin=-1, vmax=1, center=0, cmap='coolwarm', mask=matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # GridSearch\n",
    "rf = RandomForestClassifier()\n",
    "parameters ={\n",
    "    'n_estimators':[2**i for i in range(3,10)],\n",
    "    'max_depth':[2, 4, 8, 16, 32, None]\n",
    "}\n",
    "cv = GridSearchCV(rf, parameters, cv=5)\n",
    "cv.fit(train_features, train_labels.values.ravel())\n",
    "\n",
    "print_results(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate feature importance plot\n",
    "feat_imp = cv.best_estimator_.feature_importances_\n",
    "indices = np.argsort(feat_imp)\n",
    "plt.yticks(range(len(indices)), [train_features.columns[i] for i in indices])\n",
    "plt.barh(range(len(indices)), feat_imp[indices], color='r', align='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GridSearchCV automatically makes a best_estimator_ atrribute on a riffiting of the model on 100% of the data\n",
    "joblib.dump(cv.best_estimator_, 'models/mdl_reduced_features.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
